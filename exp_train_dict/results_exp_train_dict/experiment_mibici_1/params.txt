system: exp_train_dict/experiment_mibici_1
number of nodes: 12
flows: exp_train_dict/mibici_dataset_4/flows_train.npy
laplacian: exp_train_dict/mibici_dataset_4/laplacian_mibici_4.npy
number of atoms: 12
total epochs: 800
number epochs that was required: 598
regularization: l1
lambda: 0.0001
smoothness: True
gamma: 1e-05
alpha steps: 45
dictionary steps: 25
learning rate: 0.0001
batch size: 32
final loss: 0.2791719436645508
best loss: 0.26356109976768494
final time: 3.14 minutes
mean time per epoch: 0.32 seconds
tolerance: 1e-05
patience: 200
