system: exp_train_dict/experiment_mibici_1
number of nodes: 12
flows: exp_train_dict/mibici_dataset_4/flows_train.npy
laplacian: exp_train_dict/mibici_dataset_4/laplacian_mibici_4.npy
number of atoms: 12
total epochs: 1000
number epochs that was required: 548
regularization: l1
lambda: 0.0001
smoothness: True
gamma: 1e-05
alpha steps: 45
dictionary steps: 25
learning rate: 0.0001
batch size: 32
final loss: 0.2759089171886444
best loss: 0.26356109976768494
final time: 2.86 minutes
mean time per epoch: 0.31 seconds
tolerance: 1e-05
patience: 150
