{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "from scipy.sparse import csr_matrix, csc_matrix, kron, eye, diags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funtion that uses GGRF\n",
    "def vector_rf(W, d, f_vec, p_h, node, random_walks = 100, h = 100):\n",
    "    '''\n",
    "    This funtion computes the feature vector of a node using GGRF\n",
    "    Args:\n",
    "        W: Adjacency matrix\n",
    "        d: Degree vector\n",
    "        f_vec: Function to compute modulation of the random walk\n",
    "        p_h: Probability of stopping the random walk\n",
    "        node: Node of interest\n",
    "        random_walks: Number of random walks\n",
    "        h: Default value\n",
    "    Returns:\n",
    "        phi: Feature vector of the node\n",
    "    '''\n",
    "    # Initial values\n",
    "    n = h\n",
    "    phi = np.zeros(len(d))\n",
    "    m = random_walks\n",
    "    f_m = f_vec(n)\n",
    "\n",
    "    for w in range(m):\n",
    "        # Initial values for the random walk\n",
    "        load = 1.0\n",
    "        current_node = node\n",
    "        terminated = False\n",
    "        walk_lenght = 0\n",
    "        \n",
    "        # Register of the nodes visited\n",
    "        register = [current_node]\n",
    "        #print(phi[current_node])\n",
    "        counter = 0\n",
    "        #print(\"Random walk: \", w)\n",
    "        while terminated == False:\n",
    "            \n",
    "            # In case we require more values of f\n",
    "            if walk_lenght == n:\n",
    "                #print(\"Requerí mas valores de f\")\n",
    "                n = 2 * n\n",
    "                f_m = f_vec(n)\n",
    "                #print(len(f_m))\n",
    "\n",
    "            # Update the feature vector\n",
    "            #print(phi[current_node], load, f_m[walk_lenght])\n",
    "            phi[current_node] += load * f_m[walk_lenght]\n",
    "            #if walk_lenght == 3:\n",
    "            # print(load * f_m[walk_lenght], phi[current_node])\n",
    "            #print(phi)\n",
    "            # Update the walk length\n",
    "            walk_lenght += 1\n",
    "\n",
    "            # Select the next node searching in the neighbors\n",
    "            #print(current_node)\n",
    "            #neighbors = np.nonzero(W[current_node])[0]\n",
    "            neighbors = W[current_node].indices\n",
    "            #print(neighbors)\n",
    "            new_node = np.random.choice(neighbors)\n",
    "            aux = []\n",
    "            # If the node is already in the register, we search for a new one\n",
    "            while new_node in register:\n",
    "                aux.append(new_node)\n",
    "                new_node = np.random.choice(neighbors)\n",
    "                if len(aux) == len(neighbors):\n",
    "                    break\n",
    "            # If we tried all the neighbors, we select a random one\n",
    "            if len(aux) == len(neighbors):\n",
    "                new_node = np.random.choice(neighbors)\n",
    "\n",
    "            # Update the load\n",
    "            #print(current_node, new_node)\n",
    "            #print(load, d[current_node], W[current_node, new_node])\n",
    "            load = load * (d[current_node].item() / (1 - p_h))* W[current_node, new_node]\n",
    "            #print(d[current_node] / (1 - p_h))\n",
    "            #print(new_node)\n",
    "\n",
    "            # Update the current node\n",
    "            current_node = new_node\n",
    "\n",
    "            # Update the register\n",
    "            register.append(current_node)\n",
    "            counter += 1\n",
    "\n",
    "            # Check if the random walk is terminated\n",
    "            terminated = (np.random.uniform(0,0.5) < p_h)\n",
    "            if counter == 150:\n",
    "                break\n",
    "            #print(phi[node])\n",
    "            #print(phi / m)\n",
    "\n",
    "    return phi / m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2], dtype=int32)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_prueba = np.eye(5)\n",
    "m_prueba_s = csr_matrix(m_prueba)\n",
    "non_zero_indices = m_prueba_s[2].indices\n",
    "non_zero_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_f_vector(f_alpha, n):\n",
    "    '''\n",
    "    This function computes the modulation function for a given alpha function and n\n",
    "    according to the GGRF paper\n",
    "    Args:\n",
    "        f_alpha: Alpha function\n",
    "        n: Number of values to compute\n",
    "    Returns:\n",
    "        f: Modulation function of length n\n",
    "    '''\n",
    "    alpha = f_alpha(n)\n",
    "    f = np.zeros(n)\n",
    "\n",
    "    # Initial values\n",
    "    f[0] = np.sqrt(alpha[0])\n",
    "    aux = 2 * f[0]\n",
    "\n",
    "    f[1] = alpha[1] / aux\n",
    "\n",
    "    f[2] = (alpha[2] - f[1]**2) / aux\n",
    "\n",
    "    # Compute the rest of the values\n",
    "    for i in range(3, n):\n",
    "        suma = sum(f[i-p] * f[p] for p in range(1, i))\n",
    "        f[i] = (alpha[i] - suma) / aux\n",
    "\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coefficients for a Laplacian kernel\n",
    "\n",
    "def alpha_laplace(s, n, d = 1):\n",
    "    '''\n",
    "    This function computes the alpha function for a Laplacian kernel\n",
    "    Args:\n",
    "        s: Laplacian kernel parameter for regularization\n",
    "        n: Number of values to compute\n",
    "        d: Default value (power of the degree)\n",
    "    Returns:\n",
    "        alpha: Alpha function of length n\n",
    "    '''\n",
    "    alpha = np.ones(n)\n",
    "    aux1 = 0\n",
    "    aux2 = 1\n",
    "    # Recurrent formula\n",
    "    q = 1 / (1 + s**(-2))\n",
    "    #q = 1\n",
    "\n",
    "    for i in range(1, n):\n",
    "        alpha[i] = ((d + aux1) / aux2) * q * alpha[i-1]\n",
    "        aux1 += 1\n",
    "        aux2 += 1\n",
    "\n",
    "    return alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to compute the kernel matrix\n",
    "\n",
    "def kernel_graph_random_features(Wx, dx, f_vec, Px, Qx, p_h, random_walks = 100, dt = np.float32):\n",
    "    '''\n",
    "    This function computes the kernel value using the random features method\n",
    "    Args:\n",
    "        Wx: Adjacency matrix (normalized)\n",
    "        dx: Degree vector\n",
    "        f_vec: Function to compute modulation of the random walk\n",
    "        Px: Probability vector with arriving probabilities\n",
    "        Qx: Probability vector with leaving probabilities\n",
    "        p_h: Probability of stopping the random walk\n",
    "        random_walks: Number of random walks\n",
    "    Returns:\n",
    "        K: Kernel value\n",
    "    '''\n",
    "    # Define the matrices to store the feature vectors\n",
    "    K1 = np.zeros(Wx.shape, dtype = dt)\n",
    "    K2 = np.zeros(Wx.shape, dtype = dt)\n",
    "\n",
    "    # Iteration over the nodes\n",
    "    for i in range(len(dx)):\n",
    "        # Compute the feature vector for the node i\n",
    "        phi1 = vector_rf(Wx, dx, f_vec, p_h, i, random_walks)\n",
    "        phi2 = vector_rf(Wx, dx, f_vec, p_h, i, random_walks)\n",
    "        for j in range(len(dx)):\n",
    "            K1[i][j] = phi1[j]\n",
    "            K2[i][j] = phi2[j]\n",
    "\n",
    "    # Compute the estimation\n",
    "    K = K1 @ K2.T\n",
    "\n",
    "    return np.dot(Qx, np.dot(K, Px))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_trips_mibici(data_user, threshold = 5, complement = False):\n",
    "    viajes_user = data_user.groupby([data_user[['Origen_Id', 'Destino_Id']].min(axis=1), data_user[['Origen_Id', 'Destino_Id']].max(axis=1)]).size().reset_index(name='counts')\n",
    "    viajes_user.columns = ['Est_A', 'Est_B', 'counts']\n",
    "    if not complement:\n",
    "        viajes_user = viajes_user[viajes_user['counts'] >= threshold]\n",
    "    else:\n",
    "        viajes_user = viajes_user[viajes_user['counts'] < threshold]\n",
    "    if viajes_user.empty:\n",
    "        return None\n",
    "    total = viajes_user['counts'].sum()\n",
    "    viajes_user['prob'] = viajes_user['counts']/total\n",
    "    viajes_user = viajes_user.sort_values(by = 'prob', ascending = False).reset_index(drop=True)\n",
    "    return viajes_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leer_matriz(nombre_archivo):\n",
    "    matriz = []\n",
    "    with open(nombre_archivo, 'r') as archivo:\n",
    "        archivo.readline()\n",
    "        archivo.readline()\n",
    "        for linea in archivo:\n",
    "            fila = [float(valor) for valor in linea.strip().split()]\n",
    "            matriz.append(fila)\n",
    "    return matriz\n",
    "\n",
    "def encontrar_estacion(est, matriz):\n",
    "    for i in range(len(matriz)):\n",
    "        if matriz[i][0] == est:\n",
    "            return matriz[i][1], matriz[i][2]\n",
    "    return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_counter(counter_user, est, title, save = False, dir = None):\n",
    "    vertex = list(set(counter_user['Est_A'].unique().tolist() + counter_user['Est_B'].unique().tolist()))\n",
    "    opacity = np.linspace(0.1, 0.5, len(counter_user))\n",
    "    #print(vertex)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for i in vertex:\n",
    "        esta = encontrar_estacion(i, est)\n",
    "        #print(esta)\n",
    "        plt.scatter(esta[1], esta[0], color='blue')\n",
    "        plt.text(esta[1] + 0.00001, esta[0] + 0.00001, str(i), fontsize=7, ha='left', va='bottom')\n",
    "    for i in range(len(counter_user)):\n",
    "        current_trip = counter_user.iloc[i]\n",
    "        prob = current_trip[\"prob\"]\n",
    "        estA = current_trip[\"Est_A\"]\n",
    "        estB = current_trip[\"Est_B\"]\n",
    "        if estA == estB:\n",
    "            plt.scatter(encontrar_estacion(estA, est)[1], encontrar_estacion(estA, est)[0], color='red', marker='*', s=100)\n",
    "        else:\n",
    "            aux = np.array([encontrar_estacion(estA, est), encontrar_estacion(estB, est)])\n",
    "            plt.plot(aux[:,1], aux[:,0], color='black', alpha=opacity[i])\n",
    "    plt.grid()\n",
    "    plt.title(f'{title}')\n",
    "    if save:\n",
    "        directory = f'{dir}/'\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "        plt.savefig(f'{directory}/{title}.png')\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = '/home/user/Desktop/Datos/'\n",
    "#dir = '/Users/antoniomendez/Desktop/Tesis/Datos/datos_limpios/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2019 = pd.read_csv(f'{dir}mibici/2019.csv')\n",
    "data = data_2019[data_2019['Inicio_del_viaje'].str.startswith('2019-01-01')]\n",
    "data2 = data_2019[data_2019['Inicio_del_viaje'].str.startswith('2019-01-02')]\n",
    "estaciones = leer_matriz(f'{dir}/Adj_mibici/matrices_estaciones/est_2019.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_data = count_trips_mibici(data)\n",
    "counts_data2 = count_trips_mibici(data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_matrix(counter_user, normalized = False, self_loops = False):\n",
    "    if not self_loops:\n",
    "        counter_user = counter_user[counter_user['Est_A'] != counter_user['Est_B']]\n",
    "    vertex = list(set(counter_user['Est_A'].unique().tolist() + counter_user['Est_B'].unique().tolist()))\n",
    "    matrix = np.zeros((len(vertex), len(vertex)))\n",
    "    for i in range(len(counter_user)):\n",
    "        current_trip = counter_user.iloc[i]\n",
    "        count = current_trip[\"counts\"]\n",
    "        estA = current_trip[\"Est_A\"]\n",
    "        estB = current_trip[\"Est_B\"]\n",
    "\n",
    "        matrix[vertex.index(estA)][vertex.index(estB)] = count\n",
    "        matrix[vertex.index(estB)][vertex.index(estA)] = count\n",
    "    if normalized:\n",
    "        D = np.sum(matrix, axis = 1)\n",
    "        D = np.diag(D)\n",
    "        D = np.linalg.inv(np.sqrt(D))\n",
    "        matrix = np.sqrt(D) @ matrix @ np.sqrt(D)\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1 = compute_matrix(counts_data, normalized = True)\n",
    "m2 = compute_matrix(counts_data2, normalized = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00024767359147076176"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1_s = csr_matrix(m1)\n",
    "m2_s = csr_matrix(m2)\n",
    "mx = kron(m1_s, m2_s, format='csr')\n",
    "\n",
    "dx = np.sum(mx, axis = 1)\n",
    "\n",
    "px = np.ones(len(dx)) / len(dx)\n",
    "qx = np.ones(len(dx)) / len(dx)\n",
    "\n",
    "f_alpha = lambda n: alpha_laplace(0.1, n, 1)\n",
    "\n",
    "f_vec = lambda n: compute_f_vector(f_alpha, n)\n",
    "\n",
    "p_h = 0.1\n",
    "\n",
    "K = kernel_graph_random_features(mx, dx, f_vec, px, qx, p_h)\n",
    "K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_rf(W, d, f_vec, p_h, node, random_walks=100, h=100):\n",
    "    '''\n",
    "    This funtion computes the feature vector of a node using GGRF\n",
    "    Args:\n",
    "        W: Adjacency matrix\n",
    "        d: Degree vector\n",
    "        f_vec: Function to compute modulation of the random walk\n",
    "        p_h: Probability of stopping the random walk\n",
    "        node: Node of interest\n",
    "        random_walks: Number of random walks\n",
    "        h: Default value\n",
    "    Returns:\n",
    "        phi: Feature vector of the node\n",
    "    '''\n",
    "    n = h\n",
    "    phi = np.zeros(len(d), dtype=np.float32)\n",
    "    m = random_walks\n",
    "    f_m = f_vec(n).astype(np.float32)\n",
    "\n",
    "    for w in range(m):\n",
    "        load = np.float64(1.0)  # Temporary to avoid overflow\n",
    "        current_node = node\n",
    "        terminated = False\n",
    "        walk_lenght = 0\n",
    "        register = [current_node]\n",
    "        counter = 0\n",
    "\n",
    "        while not terminated:\n",
    "            if walk_lenght == n:\n",
    "                n = 2 * n\n",
    "                f_m = f_vec(n).astype(np.float32)\n",
    "\n",
    "            phi[current_node] += np.float32(load * f_m[walk_lenght])  # Convert again to float32\n",
    "\n",
    "            walk_lenght += 1\n",
    "            neighbors = W[current_node].indices\n",
    "            new_node = np.random.choice(neighbors)\n",
    "            aux = []\n",
    "            while new_node in register:\n",
    "                aux.append(new_node)\n",
    "                new_node = np.random.choice(neighbors)\n",
    "                if len(aux) == len(neighbors):\n",
    "                    break\n",
    "            if len(aux) == len(neighbors):\n",
    "                new_node = np.random.choice(neighbors)\n",
    "\n",
    "            # Calcular usando float64 y convertir el resultado a float32\n",
    "            load = np.float64(load * (d[current_node].item() / (1 - p_h)) * W[current_node, new_node])\n",
    "\n",
    "            current_node = new_node\n",
    "            register.append(current_node)\n",
    "            counter += 1\n",
    "\n",
    "            terminated = (np.random.uniform(0, 0.5) < p_h)\n",
    "            if counter == 150:\n",
    "                break\n",
    "\n",
    "    return phi / np.float32(m)\n",
    "\n",
    "\n",
    "def compute_f_vector(f_alpha, n):\n",
    "    '''\n",
    "    Calcula la función de modulación para una función alpha dada y n\n",
    "    '''\n",
    "    alpha = f_alpha(n).astype(np.float32)\n",
    "    f = np.zeros(n, dtype=np.float32)\n",
    "\n",
    "    f[0] = np.sqrt(alpha[0])\n",
    "    aux = 2 * f[0]\n",
    "    f[1] = alpha[1] / aux\n",
    "    f[2] = (alpha[2] - f[1]**2) / aux\n",
    "\n",
    "    for i in range(3, n):\n",
    "        suma = sum(f[i-p] * f[p] for p in range(1, i))\n",
    "        f[i] = (alpha[i] - suma) / aux\n",
    "\n",
    "    return f\n",
    "\n",
    "def kernel_graph_random_features(Wx, dx, f_vec, Px, Qx, p_h, random_walks=100):\n",
    "    '''\n",
    "    Calcula el valor del kernel usando el método de random features\n",
    "    '''\n",
    "    K1 = np.zeros(Wx.shape, dtype=np.float32)\n",
    "    K2 = np.zeros(Wx.shape, dtype=np.float32)\n",
    "\n",
    "    for i in range(len(dx)):\n",
    "        phi1 = vector_rf(Wx, dx, f_vec, p_h, i, random_walks).astype(np.float32)\n",
    "        phi2 = vector_rf(Wx, dx, f_vec, p_h, i, random_walks).astype(np.float32)\n",
    "        for j in range(len(dx)):\n",
    "            K1[i][j] = phi1[j]\n",
    "            K2[i][j] = phi2[j]\n",
    "\n",
    "    K = K1 @ K2.T\n",
    "    return np.dot(Qx, np.dot(K, Px).astype(np.float32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "mx_ = np.kron(m1, m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00021280588223330404"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1_s = csr_matrix(m1)\n",
    "m2_s = csr_matrix(m2)\n",
    "mx = kron(m1_s, m2_s, format='csr')\n",
    "\n",
    "dx = np.sum(mx, axis = 1)\n",
    "\n",
    "px = np.ones(len(dx)) / len(dx)\n",
    "qx = np.ones(len(dx)) / len(dx)\n",
    "\n",
    "f_alpha = lambda n: alpha_laplace(0.1, n, 1)\n",
    "\n",
    "f_vec = lambda n: compute_f_vector(f_alpha, n)\n",
    "\n",
    "p_h = 0.3\n",
    "\n",
    "K = kernel_graph_random_features(mx, dx, f_vec, px, qx, p_h)\n",
    "K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0008926800238048007"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bytes de la matriz dispersa mx\n",
    "peso_mx = mx.data.nbytes\n",
    "\n",
    "# bytes de la matriz densa mx_\n",
    "peso_mx_ = mx_.nbytes\n",
    "\n",
    "peso_mx/peso_mx_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
