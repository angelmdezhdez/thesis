{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funtion that computes the ij entry of the kronecker product of A and B\n",
    "\n",
    "def kronecker(A,B,i,j):\n",
    "    return A[i//B.shape[0],j//B.shape[1]]*B[i%B.shape[0],j%B.shape[1]]\n",
    "\n",
    "# function that finds neigbors in the kronecker product of A and B\n",
    "\n",
    "def neighbors_kron(A,B,i):\n",
    "    n = []\n",
    "    for j in range(A.shape[1]*B.shape[1]):\n",
    "        if kronecker(A,B,i,j) != 0:\n",
    "            n.append(j)\n",
    "    return n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funtion that uses GGRF\n",
    "def vector_rf_kron(W1, W2, d, f_vec, p_h, node, random_walks = 100, h = 100):\n",
    "    '''\n",
    "    This funtion computes the feature vector of a node using GGRF\n",
    "    Args:\n",
    "        W1: Adjacency matrix of the first graph\n",
    "        W2: Adjacency matrix of the second graph\n",
    "        d: Degree vector\n",
    "        f_vec: Function to compute modulation of the random walk\n",
    "        p_h: Probability of stopping the random walk\n",
    "        node: Node of interest\n",
    "        random_walks: Number of random walks\n",
    "        h: Default value\n",
    "    Returns:\n",
    "        phi: Feature vector of the node\n",
    "    '''\n",
    "    # Initial values\n",
    "    n = h\n",
    "    phi = np.zeros(len(d))\n",
    "    m = random_walks\n",
    "    f_m = f_vec(n)\n",
    "\n",
    "    for w in range(m):\n",
    "        # Initial values for the random walk\n",
    "        load = 1\n",
    "        current_node = node\n",
    "        terminated = False\n",
    "        walk_lenght = 0\n",
    "        \n",
    "        # Register of the nodes visited\n",
    "        register = [current_node]\n",
    "        counter = 0\n",
    "        while terminated == False:\n",
    "            \n",
    "            # In case we require more values of f\n",
    "            if walk_lenght == n:\n",
    "                #print(\"Requer√≠ mas valores de f\")\n",
    "                n = 2 * n\n",
    "                f_m = f_vec(n)\n",
    "\n",
    "            # Update the feature vector\n",
    "            phi[current_node] += load * f_m[walk_lenght]\n",
    "            # Update the walk length\n",
    "            walk_lenght += 1\n",
    "\n",
    "            # Select the next node searching in the neighbors\n",
    "            neighbors = neighbors_kron(W1,W2,current_node)\n",
    "            new_node = np.random.choice(neighbors)\n",
    "            aux = []\n",
    "            # If the node is already in the register, we search for a new one\n",
    "            while new_node in register:\n",
    "                aux.append(new_node)\n",
    "                new_node = np.random.choice(neighbors)\n",
    "                if len(aux) == len(neighbors):\n",
    "                    break\n",
    "            # If we tried all the neighbors, we select a random one\n",
    "            if len(aux) == len(neighbors):\n",
    "                new_node = np.random.choice(neighbors)\n",
    "\n",
    "            # Update the load\n",
    "            load = load * (d[current_node] / (1 - p_h))* kronecker(W1,W2,current_node,new_node)\n",
    "\n",
    "            # Update the current node\n",
    "            current_node = new_node\n",
    "\n",
    "            # Update the register\n",
    "            register.append(current_node)\n",
    "            counter += 1\n",
    "\n",
    "            # Check if the random walk is terminated\n",
    "            terminated = (np.random.uniform(0,0.5) < p_h)\n",
    "            if counter == 150:\n",
    "                break\n",
    "\n",
    "    return phi / m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modulation function\n",
    "def compute_f_vector(f_alpha, n):\n",
    "    '''\n",
    "    This function computes the modulation function for a given alpha function and n\n",
    "    according to the GGRF paper\n",
    "    Args:\n",
    "        f_alpha: Alpha function\n",
    "        n: Number of values to compute\n",
    "    Returns:\n",
    "        f: Modulation function of length n\n",
    "    '''\n",
    "    alpha = f_alpha(n)\n",
    "    f = np.zeros(n)\n",
    "\n",
    "    # Initial values\n",
    "    f[0] = np.sqrt(alpha[0])\n",
    "    aux = 2 * f[0]\n",
    "\n",
    "    f[1] = alpha[1] / aux\n",
    "\n",
    "    f[2] = (alpha[2] - f[1]**2) / aux\n",
    "\n",
    "    # Compute the rest of the values\n",
    "    for i in range(3, n):\n",
    "        suma = sum(f[i-p] * f[p] for p in range(1, i))\n",
    "        f[i] = (alpha[i] - suma) / aux\n",
    "\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coefficients for a Laplacian kernel\n",
    "\n",
    "def alpha_laplace(s, n, d = 1):\n",
    "    '''\n",
    "    This function computes the alpha function for a Laplacian kernel\n",
    "    Args:\n",
    "        s: Laplacian kernel parameter for regularization\n",
    "        n: Number of values to compute\n",
    "        d: Default value (power of the degree)\n",
    "    Returns:\n",
    "        alpha: Alpha function of length n\n",
    "    '''\n",
    "    alpha = np.ones(n)\n",
    "    aux1 = 0\n",
    "    aux2 = 1\n",
    "    # Recurrent formula\n",
    "    q = 1 / (1 + s**(-2))\n",
    "    #q = 1\n",
    "\n",
    "    for i in range(1, n):\n",
    "        alpha[i] = ((d + aux1) / aux2) * q * alpha[i-1]\n",
    "        aux1 += 1\n",
    "        aux2 += 1\n",
    "\n",
    "    return alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kernel_graph_random_features(W1, W2, dx, f_vec, Px, Qx, p_h, random_walks = 100):\n",
    "    '''\n",
    "    This function computes the kernel value using the random features method\n",
    "    Args:\n",
    "        W1: Adjacency matrix of the first graph\n",
    "        W2: Adjacency matrix of the second graph\n",
    "        dx: Degree vector\n",
    "        f_vec: Function to compute modulation of the random walk\n",
    "        Px: Probability vector with arriving probabilities\n",
    "        Qx: Probability vector with leaving probabilities\n",
    "        p_h: Probability of stopping the random walk\n",
    "        random_walks: Number of random walks\n",
    "    Returns:\n",
    "        K: Kernel value\n",
    "    '''\n",
    "    # Define the matrices to store the feature vectors\n",
    "    K1 = []\n",
    "    K2 = []\n",
    "\n",
    "    # Iteration over the nodes\n",
    "    for i in range(len(dx)):\n",
    "        # Compute the feature vector for the node i\n",
    "        phi1 = vector_rf_kron(W1, W2, dx, f_vec, p_h, i, random_walks)\n",
    "        K1.append(phi1)\n",
    "        phi1 = vector_rf_kron(W1, W2, dx, f_vec, p_h, i, random_walks)\n",
    "        K2.append(phi1)\n",
    "\n",
    "    # Compute the estimation\n",
    "    K = np.dot(K1, np.transpose(K2))\n",
    "\n",
    "    return np.dot(Qx, np.dot(K, Px))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to compute the kernel matrix\n",
    "\n",
    "def kernel_graph_random_features1(W1, W2, dx, f_vec, Px, Qx, p_h, random_walks = 100):\n",
    "    '''\n",
    "    This function computes the kernel value using the random features method with changes to\n",
    "    save memory\n",
    "    Args:\n",
    "        W1: Adjacency matrix of the first graph\n",
    "        W2: Adjacency matrix of the second graph\n",
    "        dx: Degree vector\n",
    "        f_vec: Function to compute modulation of the random walk\n",
    "        Px: Probability vector with arriving probabilities\n",
    "        Qx: Probability vector with leaving probabilities\n",
    "        p_h: Probability of stopping the random walk\n",
    "        random_walks: Number of random walks\n",
    "    Returns:\n",
    "        K: Kernel value\n",
    "    '''\n",
    "    # Initial value\n",
    "    K = 0\n",
    "    vectors = []\n",
    "    # Compute and save the first vector\n",
    "    phi_0 = vector_rf_kron(W1, W2, dx, f_vec, p_h, 0, random_walks)\n",
    "    aux = np.zeros(len(phi_0))\n",
    "    for i in range(W1.shape[1]*W2.shape[1]):\n",
    "        phi_i = vector_rf_kron(W1, W2, dx, f_vec, p_h, i, random_walks)\n",
    "        vectors.append(phi_i)\n",
    "        aux[i] = np.dot(phi_0, phi_i)\n",
    "    \n",
    "    # Add the first term to the kernel\n",
    "    K += Qx[0] * np.dot(Px, aux)\n",
    "\n",
    "    # Compute the rest of the terms\n",
    "    for i in range(1, W1.shape[1]*W2.shape[1]):\n",
    "        phi_i = vector_rf_kron(W1, W2, dx, f_vec, p_h, i, random_walks)\n",
    "        aux = np.zeros(len(phi_i))\n",
    "        for j in range(W1.shape[1]*W2.shape[1]):\n",
    "            aux[j] = np.dot(phi_i, vectors[j])\n",
    "        # Add the term to the kernel\n",
    "        K += Qx[i] * np.dot(Px, aux)\n",
    "\n",
    "    return K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to compute the kernel matrix\n",
    "\n",
    "def kernel_graph_random_features2(W1, W2, dx, f_vec, Px, Qx, p_h, random_walks = 100):\n",
    "    '''\n",
    "    This function computes the kernel value using the random features method savig the vectors\n",
    "    to solve the ram problem\n",
    "    Args:\n",
    "        W1: Adjacency matrix of the first graph\n",
    "        W2: Adjacency matrix of the second graph\n",
    "        dx: Degree vector\n",
    "        f_vec: Function to compute modulation of the random walk\n",
    "        Px: Probability vector with arriving probabilities\n",
    "        Qx: Probability vector with leaving probabilities\n",
    "        p_h: Probability of stopping the random walk\n",
    "        random_walks: Number of random walks\n",
    "    Returns:\n",
    "        K: Kernel value\n",
    "    '''\n",
    "    # Initial value\n",
    "    K = 0\n",
    "    # Create the directory to save the vectors\n",
    "    os.makedirs('vectors', exist_ok=True)\n",
    "    # Compute and save the first vector\n",
    "    phi_0 = vector_rf_kron(W1, W2, dx, f_vec, p_h, 0, random_walks)\n",
    "    aux = np.zeros(len(phi_0))\n",
    "    for i in range(W1.shape[1]*W2.shape[1]):\n",
    "        phi_i = vector_rf_kron(W1, W2, dx, f_vec, p_h, i, random_walks)\n",
    "        np.save('vectors/phi_{}'.format(i), phi_i)\n",
    "        aux[i] = np.dot(phi_0, phi_i)\n",
    "    \n",
    "    # Add the first term to the kernel\n",
    "    K += Qx[0] * np.dot(Px, aux)\n",
    "\n",
    "    # Compute the rest of the terms\n",
    "    for i in range(1, W1.shape[1]*W2.shape[1]):\n",
    "        phi_i = vector_rf_kron(W1, W2, dx, f_vec, p_h, i, random_walks)\n",
    "        aux = np.zeros(len(phi_i))\n",
    "        for j in range(W1.shape[1]*W2.shape[1]):\n",
    "            # we only have to load the vectors from the disk\n",
    "            phi_j = np.load('vectors/phi_{}.npy'.format(j))\n",
    "            aux[j] = np.dot(phi_i, phi_j)\n",
    "        # Add the term to the kernel\n",
    "        K += Qx[i] * np.dot(Px, aux)\n",
    "    # Remove the directory\n",
    "    os.system('rm -r vectors')\n",
    "\n",
    "    return K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_phi_and_dot(phi_0, W1, W2, dx, f_vec, p_h, index, random_walks):\n",
    "    \"\"\"\n",
    "    Compute phi_i and its dot product with phi_0\n",
    "    \"\"\"\n",
    "    phi_i = vector_rf_kron(W1, W2, dx, f_vec, p_h, index, random_walks)\n",
    "    return index, phi_i, np.dot(phi_0, phi_i)\n",
    "\n",
    "def kernel_graph_random_features_parallel(W1, W2, dx, f_vec, Px, Qx, p_h, random_walks=100):\n",
    "    '''\n",
    "    Computes the kernel value using the random features method with parallelization\n",
    "    Args:\n",
    "        W1: Adjacency matrix of the first graph\n",
    "        W2: Adjacency matrix of the second graph\n",
    "        dx: Degree vector\n",
    "        f_vec: Function to compute modulation of the random walk\n",
    "        Px: Probability vector with arriving probabilities\n",
    "        Qx: Probability vector with leaving probabilities\n",
    "        p_h: Probability of stopping the random walk\n",
    "        random_walks: Number of random walks\n",
    "    Returns:\n",
    "        K: Kernel value\n",
    "    '''\n",
    "    K = 0\n",
    "    n = W1.shape[1] * W2.shape[1]\n",
    "    \n",
    "    # Compute phi_0\n",
    "    phi_0 = vector_rf_kron(W1, W2, dx, f_vec, p_h, 0, random_walks)\n",
    "    \n",
    "    # Parallel computation of phi_i and dot(phi_0, phi_i)\n",
    "    with ProcessPoolExecutor() as executor:\n",
    "        futures = [\n",
    "            executor.submit(compute_phi_and_dot, phi_0, W1, W2, dx, f_vec, p_h, i, random_walks)\n",
    "            for i in range(n)\n",
    "        ]\n",
    "        results = [f.result() for f in futures]\n",
    "    \n",
    "    # Process results for the first term\n",
    "    phi_dict = {index: phi_i for index, phi_i, dot_value in results}\n",
    "    aux = np.array([dot_value for _, _, dot_value in results])\n",
    "    K += Qx[0] * np.dot(Px, aux)\n",
    "\n",
    "    # Compute the rest of the terms in parallel\n",
    "    def compute_aux_and_contrib(phi_i, i):\n",
    "        aux = np.zeros(n)\n",
    "        for j in range(n):\n",
    "            aux[j] = np.dot(phi_i, phi_dict[j])\n",
    "        return Qx[i] * np.dot(Px, aux)\n",
    "\n",
    "    with ProcessPoolExecutor() as executor:\n",
    "        futures = [\n",
    "            executor.submit(compute_aux_and_contrib, phi_dict[i], i)\n",
    "            for i in range(1, n)\n",
    "        ]\n",
    "        results = [f.result() for f in futures]\n",
    "    \n",
    "    # Sum all contributions\n",
    "    K += sum(results)\n",
    "\n",
    "    return K\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_trips_mibici(data_user, threshold = 5, complement = False):\n",
    "    viajes_user = data_user.groupby([data_user[['Origen_Id', 'Destino_Id']].min(axis=1), data_user[['Origen_Id', 'Destino_Id']].max(axis=1)]).size().reset_index(name='counts')\n",
    "    viajes_user.columns = ['Est_A', 'Est_B', 'counts']\n",
    "    if not complement:\n",
    "        viajes_user = viajes_user[viajes_user['counts'] >= threshold]\n",
    "    else:\n",
    "        viajes_user = viajes_user[viajes_user['counts'] < threshold]\n",
    "    if viajes_user.empty:\n",
    "        return None\n",
    "    total = viajes_user['counts'].sum()\n",
    "    viajes_user['prob'] = viajes_user['counts']/total\n",
    "    viajes_user = viajes_user.sort_values(by = 'prob', ascending = False).reset_index(drop=True)\n",
    "    return viajes_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_matrix(counter_user, normalized = False, self_loops = False):\n",
    "    if not self_loops:\n",
    "        counter_user = counter_user[counter_user['Est_A'] != counter_user['Est_B']]\n",
    "    vertex = list(set(counter_user['Est_A'].unique().tolist() + counter_user['Est_B'].unique().tolist()))\n",
    "    matrix = np.zeros((len(vertex), len(vertex)))\n",
    "    for i in range(len(counter_user)):\n",
    "        current_trip = counter_user.iloc[i]\n",
    "        count = current_trip[\"counts\"]\n",
    "        estA = current_trip[\"Est_A\"]\n",
    "        estB = current_trip[\"Est_B\"]\n",
    "\n",
    "        matrix[vertex.index(estA)][vertex.index(estB)] = count\n",
    "        matrix[vertex.index(estB)][vertex.index(estA)] = count\n",
    "    if normalized:\n",
    "        D = np.sum(matrix, axis = 1)\n",
    "        D = np.diag(D)\n",
    "        D = np.linalg.inv(np.sqrt(D))\n",
    "        matrix = np.sqrt(D) @ matrix @ np.sqrt(D)\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to compute the degree vector of a kronecker product\n",
    "\n",
    "def degree_kron(W1, W2):\n",
    "    return np.kron(W1.sum(axis = 1), W2.sum(axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dir = '/home/user/Desktop/Datos/'\n",
    "dir = '/Users/antoniomendez/Desktop/Tesis/Datos/datos_limpios/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2019 = pd.read_csv(f'{dir}mibici/2019.csv')\n",
    "data = data_2019[data_2019['Inicio_del_viaje'].str.startswith('2019-01-01')]\n",
    "data2 = data_2019[data_2019['Inicio_del_viaje'].str.startswith('2019-01-02')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_data = count_trips_mibici(data)\n",
    "counts_data2 = count_trips_mibici(data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1 = compute_matrix(counts_data, normalized = True)\n",
    "m2 = compute_matrix(counts_data2, normalized = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0002389622548040926\n"
     ]
    }
   ],
   "source": [
    "dx = degree_kron(m1, m2)\n",
    "\n",
    "px = np.ones(len(dx)) / len(dx)\n",
    "qx = np.ones(len(dx)) / len(dx)\n",
    "\n",
    "f_alpha = lambda n: alpha_laplace(0.1, n, 1)\n",
    "\n",
    "f_vec = lambda n: compute_f_vector(f_alpha, n)\n",
    "\n",
    "p_h = 0.15\n",
    "\n",
    "K = kernel_graph_random_features(m1, m2, dx, f_vec, px, qx, p_h)\n",
    "print(K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "def send_message(message, channel):\n",
    "    requests.post(f\"https://ntfy.sh/{channel}\",\n",
    "        data=message.encode(encoding='utf-8'))\n",
    "    \n",
    "send_message(f\"Kernel value: {K}\", \"My_Computer\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
