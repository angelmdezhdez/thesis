{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import requests\n",
    "import multiprocessing\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Floyd-Warshall algorithm\n",
    "def floyd_warshall(AdjMatrix):\n",
    "    n = len(AdjMatrix)\n",
    "    cost = np.copy(AdjMatrix)\n",
    "    cost[cost == 0] = np.inf\n",
    "    for k in range(n):\n",
    "        for i in range(n):\n",
    "            for j in range(n):\n",
    "                cost[i, j] = min(cost[i, j], cost[i, k] + cost[k, j])\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shortest_path_kernel1(S1, S2, k_walk):\n",
    "    # Obtener índices donde las entradas son finitas\n",
    "    indices_S1 = np.transpose(np.triu_indices_from(S1))\n",
    "    indices_S2 = np.transpose(np.triu_indices_from(S2))\n",
    "    \n",
    "    # Filtrar valores finitos\n",
    "    indices_S1 = indices_S1[np.isfinite(S1[indices_S1[:, 0], indices_S1[:, 1]])]\n",
    "    indices_S2 = indices_S2[np.isfinite(S2[indices_S2[:, 0], indices_S2[:, 1]])]\n",
    "\n",
    "    # Convertir las entradas relevantes en arrays\n",
    "    S1_finite = S1[indices_S1[:, 0], indices_S1[:, 1]]\n",
    "    S2_finite = S2[indices_S2[:, 0], indices_S2[:, 1]]\n",
    "\n",
    "    # Calcular el kernel con producto cartesiano sin crear listas grandes\n",
    "    K = 0\n",
    "    for d1 in S1_finite:\n",
    "        for d2 in S2_finite:\n",
    "            K += k_walk(d1, d2)\n",
    "\n",
    "    return K\n",
    "\n",
    "def shortest_path_kernel2(S1, S2, k_walk):\n",
    "    # Obtener índices donde las entradas son finitas\n",
    "    indices_S1 = np.transpose(np.triu_indices_from(S1))\n",
    "    indices_S2 = np.transpose(np.triu_indices_from(S2))\n",
    "    \n",
    "    # Filtrar valores finitos\n",
    "    indices_S1 = indices_S1[np.isfinite(S1[indices_S1[:, 0], indices_S1[:, 1]])]\n",
    "    indices_S2 = indices_S2[np.isfinite(S2[indices_S2[:, 0], indices_S2[:, 1]])]\n",
    "\n",
    "    # Convertir las entradas relevantes en arrays\n",
    "    S1_finite = S1[indices_S1[:, 0], indices_S1[:, 1]]\n",
    "    S2_finite = S2[indices_S2[:, 0], indices_S2[:, 1]]\n",
    "    \n",
    "    # Calcular el kernel con producto cartesiano\n",
    "    K = np.sum([k_walk(d1, d2) for d1 in S1_finite for d2 in S2_finite])\n",
    "    \n",
    "    return K\n",
    "\n",
    "def shortest_path_kernel3(S1, S2, k_walk):\n",
    "        # Obtener índices donde las entradas son finitas\n",
    "    indices_S1 = np.transpose(np.triu_indices_from(S1))\n",
    "    indices_S2 = np.transpose(np.triu_indices_from(S2))\n",
    "    \n",
    "    # Filtrar valores finitos\n",
    "    indices_S1 = indices_S1[np.isfinite(S1[indices_S1[:, 0], indices_S1[:, 1]])]\n",
    "    indices_S2 = indices_S2[np.isfinite(S2[indices_S2[:, 0], indices_S2[:, 1]])]\n",
    "\n",
    "    # Convertir las entradas relevantes en arrays\n",
    "    S1_finite = S1[indices_S1[:, 0], indices_S1[:, 1]]\n",
    "    S2_finite = S2[indices_S2[:, 0], indices_S2[:, 1]]\n",
    "    \n",
    "    # Calcular el kernel con producto cartesiano\n",
    "    K = np.sum(np.fromiter((k_walk(i, j) for i in S1_finite for j in S2_finite), dtype=float))\n",
    "    return K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _compute_kernel_element(args):\n",
    "    \"\"\"Helper function for parallel computation of kernel values.\"\"\"\n",
    "    d1, S2_finite, k_walk = args\n",
    "    return sum(k_walk(d1, d2) for d2 in S2_finite)\n",
    "\n",
    "def parallel_shortest_path_kernel1(S1, S2, k_walk, num_processes=min(multiprocessing.cpu_count(), 8)):\n",
    "    \"\"\"\n",
    "    Computes the shortest path kernel between two matrices using parallel processing.\n",
    "    \n",
    "    Parameters:\n",
    "    S1, S2: 2D numpy arrays (matrices of shortest paths)\n",
    "    k_walk: kernel function that takes two distances as input\n",
    "    num_processes: int, number of processes to use for parallelization\n",
    "    \n",
    "    Returns:\n",
    "    K: kernel value\n",
    "    \"\"\"\n",
    "    # Obtain indices where the entries are finite\n",
    "    indices_S1 = np.transpose(np.triu_indices_from(S1))\n",
    "    indices_S2 = np.transpose(np.triu_indices_from(S2))\n",
    "\n",
    "    # Filter finite values\n",
    "    indices_S1 = indices_S1[np.isfinite(S1[indices_S1[:, 0], indices_S1[:, 1]])]\n",
    "    indices_S2 = indices_S2[np.isfinite(S2[indices_S2[:, 0], indices_S2[:, 1]])]\n",
    "\n",
    "    # Convert the relevant entries into arrays\n",
    "    S1_finite = S1[indices_S1[:, 0], indices_S1[:, 1]]\n",
    "    S2_finite = S2[indices_S2[:, 0], indices_S2[:, 1]]\n",
    "\n",
    "    # Prepare arguments for parallel computation\n",
    "    args = [(d1, S2_finite, k_walk) for d1 in S1_finite]\n",
    "\n",
    "    # Use multiprocessing Pool to compute kernel values in parallel\n",
    "    with multiprocessing.Pool(processes=num_processes) as pool:\n",
    "        results = pool.map(_compute_kernel_element, args)\n",
    "\n",
    "    # Sum up the results to get the final kernel value\n",
    "    K = sum(results)\n",
    "    return K\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHORTEST PATH KERNEL\n",
    "\n",
    "def shortest_path_kernel1(S1, S2, k_walk):\n",
    "    # Obtener índices donde las entradas son finitas\n",
    "    indices_S1 = np.transpose(np.triu_indices_from(S1))\n",
    "    indices_S2 = np.transpose(np.triu_indices_from(S2))\n",
    "    \n",
    "    # Filtrar valores finitos\n",
    "    indices_S1 = indices_S1[np.isfinite(S1[indices_S1[:, 0], indices_S1[:, 1]])]\n",
    "    indices_S2 = indices_S2[np.isfinite(S2[indices_S2[:, 0], indices_S2[:, 1]])]\n",
    "\n",
    "    # Convertir las entradas relevantes en arrays\n",
    "    S1_finite = S1[indices_S1[:, 0], indices_S1[:, 1]]\n",
    "    S2_finite = S2[indices_S2[:, 0], indices_S2[:, 1]]\n",
    "\n",
    "    # Calcular el kernel con producto cartesiano sin crear listas grandes\n",
    "    K = 0\n",
    "    for d1 in S1_finite:\n",
    "        for d2 in S2_finite:\n",
    "            K += k_walk(d1, d2)\n",
    "\n",
    "    return K\n",
    "\n",
    "def shortest_path_kernel2(S1, S2, k_walk):\n",
    "    K = 0\n",
    "    n = len(S1)\n",
    "    m = len(S2)\n",
    "    for i in range(n):\n",
    "        for j in range(i, n):\n",
    "            for ii in range(m):\n",
    "                for jj in range(ii, m):\n",
    "                    if np.isfinite(S1[i, j]) and np.isfinite(S2[ii, jj]):\n",
    "                        K += k_walk(S1[i, j], S2[ii, jj])\n",
    "    return K\n",
    "\n",
    "def shortest_path_kernel(S1, S2, k_walk):\n",
    "    try:\n",
    "        return shortest_path_kernel1(S1, S2, k_walk)\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}, trying another approach\")\n",
    "        return shortest_path_kernel2(S1, S2, k_walk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dirac_kernel(a, b):\n",
    "    return 1 if a == b else 0\n",
    "\n",
    "def gaussian_kernel(a,b, sigma = 1/10):\n",
    "    return np.exp(-((a-b)**2)*sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_trips_mibici(data_user, threshold = 5, complement = False):\n",
    "    viajes_user = data_user.groupby([data_user[['Origen_Id', 'Destino_Id']].min(axis=1), data_user[['Origen_Id', 'Destino_Id']].max(axis=1)]).size().reset_index(name='counts')\n",
    "    viajes_user.columns = ['Est_A', 'Est_B', 'counts']\n",
    "    if not complement:\n",
    "        viajes_user = viajes_user[viajes_user['counts'] >= threshold]\n",
    "    else:\n",
    "        viajes_user = viajes_user[viajes_user['counts'] < threshold]\n",
    "    if viajes_user.empty:\n",
    "        return None\n",
    "    total = viajes_user['counts'].sum()\n",
    "    viajes_user['prob'] = viajes_user['counts']/total\n",
    "    viajes_user = viajes_user.sort_values(by = 'prob', ascending = False).reset_index(drop=True)\n",
    "    return viajes_user\n",
    "\n",
    "def compute_matrix(counter_user, normalized = False, self_loops = False):\n",
    "    if not self_loops:\n",
    "        counter_user = counter_user[counter_user['Est_A'] != counter_user['Est_B']]\n",
    "    vertex = list(set(counter_user['Est_A'].unique().tolist() + counter_user['Est_B'].unique().tolist()))\n",
    "    matrix = np.zeros((len(vertex), len(vertex)))\n",
    "    for i in range(len(counter_user)):\n",
    "        current_trip = counter_user.iloc[i]\n",
    "        count = current_trip[\"counts\"]\n",
    "        estA = current_trip[\"Est_A\"]\n",
    "        estB = current_trip[\"Est_B\"]\n",
    "\n",
    "        matrix[vertex.index(estA)][vertex.index(estB)] = count\n",
    "        matrix[vertex.index(estB)][vertex.index(estA)] = count\n",
    "    if normalized:\n",
    "        D = np.sum(matrix, axis = 1)\n",
    "        D = np.diag(D)\n",
    "        D = np.linalg.inv(np.sqrt(D))\n",
    "        matrix = D @ matrix @ D\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to compute the gram matrix\n",
    "\n",
    "def gram_matrix(data, k_function, normalized = False, save = False, directory = None):\n",
    "    \"\"\"This function computes the gram matrix of the data using the kernel function k_function\n",
    "    Parameters:\n",
    "    data: list of matrices\n",
    "    k_function: kernel function which takes two matrices as input\n",
    "    normalized: boolean, if True the gram matrix is normalized\n",
    "    save: boolean, if True the gram matrix is saved in the current directory\n",
    "    directory: string, directory where the gram matrix is saved\n",
    "    Returns:\n",
    "    gram: gram matrix of the data\n",
    "    \"\"\"\n",
    "    n = len(data)\n",
    "    gram = np.zeros((n, n))\n",
    "    for i in range(n):\n",
    "        for j in range(i, n):\n",
    "            gram[i, j] = k_function(data[i], data[j])\n",
    "            gram[j, i] = gram[i, j]\n",
    "    if normalized:\n",
    "        D = np.diag(np.diag(gram))\n",
    "        D = np.linalg.inv(np.sqrt(D))\n",
    "        gram = D @ gram @ D\n",
    "    if save:\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "        np.save(directory + 'gram_matrix.npy', gram)\n",
    "    return gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dir = '/home/user/Desktop/Datos/'\n",
    "dir = '/Users/antoniomendez/Desktop/Tesis/Datos/datos_limpios/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2019 = pd.read_csv(f'{dir}mibici/2019.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando fecha:  2019-01-01\n",
      "Procesando fecha:  2019-01-02\n",
      "Procesando fecha:  2019-01-03\n"
     ]
    }
   ],
   "source": [
    "# generate data\n",
    "dates = [f\"2019-01-{str(i).zfill(2)}\" for i in range(1, 4)]\n",
    "data = []\n",
    "for date in dates:\n",
    "    print(\"Procesando fecha: \", date)\n",
    "    current_data = data_2019[data_2019['Inicio_del_viaje'].str.startswith(date)]\n",
    "    current_counter = count_trips_mibici(current_data)\n",
    "    current_matrix = compute_matrix(current_counter, self_loops=True)\n",
    "    current_s = floyd_warshall(current_matrix)\n",
    "    data.append(current_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tests with the original funcions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time kernel 1:  25.920093774795532\n",
      "[[2.134000e+03 3.461800e+04 4.316500e+04]\n",
      " [3.461800e+04 2.293064e+06 2.805713e+06]\n",
      " [4.316500e+04 2.805713e+06 3.509210e+06]]\n",
      "Time kernel 2:  38.85942792892456\n",
      "[[2.134000e+03 3.461800e+04 4.316500e+04]\n",
      " [3.461800e+04 2.293064e+06 2.805713e+06]\n",
      " [4.316500e+04 2.805713e+06 3.509210e+06]]\n",
      "Time kernel 3:  37.73068904876709\n",
      "[[2.134000e+03 3.461800e+04 4.316500e+04]\n",
      " [3.461800e+04 2.293064e+06 2.805713e+06]\n",
      " [4.316500e+04 2.805713e+06 3.509210e+06]]\n"
     ]
    }
   ],
   "source": [
    "# tests\n",
    "\n",
    "kernel1 = lambda x, y: shortest_path_kernel1(x, y, dirac_kernel)\n",
    "start = time.time()\n",
    "gram = gram_matrix(data, kernel1)\n",
    "print(\"Time kernel 1: \", time.time() - start)\n",
    "print(gram)\n",
    "\n",
    "kernel2 = lambda x, y: shortest_path_kernel2(x, y, dirac_kernel)\n",
    "start = time.time()\n",
    "gram = gram_matrix(data, kernel2)\n",
    "print(\"Time kernel 2: \", time.time() - start)\n",
    "print(gram)\n",
    "\n",
    "kernel3 = lambda x, y: shortest_path_kernel3(x, y, dirac_kernel)\n",
    "start = time.time()\n",
    "gram = gram_matrix(data, kernel3)\n",
    "print(\"Time kernel 3: \", time.time() - start)\n",
    "print(gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time kernel 1:  217.63507294654846\n",
      "[[6.06383916e+03 1.81904621e+05 2.27235929e+05]\n",
      " [1.81904621e+05 1.34589840e+07 1.64293635e+07]\n",
      " [2.27235929e+05 1.64293635e+07 2.02710210e+07]]\n",
      "Time kernel 2:  225.69025683403015\n",
      "[[6.06383916e+03 1.81904621e+05 2.27235929e+05]\n",
      " [1.81904621e+05 1.34589840e+07 1.64293636e+07]\n",
      " [2.27235929e+05 1.64293636e+07 2.02710210e+07]]\n",
      "Time kernel 3:  214.90464687347412\n",
      "[[6.06383916e+03 1.81904621e+05 2.27235929e+05]\n",
      " [1.81904621e+05 1.34589840e+07 1.64293636e+07]\n",
      " [2.27235929e+05 1.64293636e+07 2.02710210e+07]]\n"
     ]
    }
   ],
   "source": [
    "s = 0.07856742013183861\n",
    "\n",
    "kernel1 = lambda x, y: shortest_path_kernel1(x, y,lambda a, b: gaussian_kernel(a, b, s))\n",
    "start = time.time()\n",
    "gram = gram_matrix(data, kernel1)\n",
    "print(\"Time kernel 1: \", time.time() - start)\n",
    "print(gram)\n",
    "\n",
    "kernel2 = lambda x, y: shortest_path_kernel2(x, y, lambda a, b: gaussian_kernel(a, b, s))\n",
    "start = time.time()\n",
    "gram = gram_matrix(data, kernel2)\n",
    "print(\"Time kernel 2: \", time.time() - start)\n",
    "print(gram)\n",
    "\n",
    "kernel3 = lambda x, y: shortest_path_kernel3(x, y, lambda a, b: gaussian_kernel(a, b, s))\n",
    "start = time.time()\n",
    "gram = gram_matrix(data, kernel3)\n",
    "print(\"Time kernel 3: \", time.time() - start)\n",
    "print(gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "requests.post(\"https://ntfy.sh/My_Computer\", data=\"Proceso terminado\".encode('utf-8'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
